"""
ä»»åŠ¡è°ƒåº¦ç®¡ç†å™¨
ä½¿ç”¨ APScheduler è¿›è¡Œå®šæ—¶è°ƒåº¦ï¼Œé€šè¿‡é˜Ÿåˆ—è§£è€¦è°ƒåº¦å’Œæ‰§è¡Œ
"""

import json
import queue
import threading
import time
import os
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Callable, Set
from datetime import datetime, timedelta

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger

from core.models import SyncTask, TaskStatus, ScheduleType, StrmTask
from core.worker import FileSyncer
from core.database import Database

# é…ç½®æ–‡ä»¶ Schema ç‰ˆæœ¬å·ï¼Œç”¨äºå…¼å®¹æ—§ç‰ˆé…ç½®å¹¶åšè¿ç§»
CONFIG_SCHEMA_VERSION = 1


class TaskScheduler:
    """ä»»åŠ¡è°ƒåº¦ç®¡ç†å™¨ï¼ˆæ”¯æŒå¤šä»»åŠ¡ç³»ç»Ÿï¼‰"""
    
    def __init__(self, config_path: str = "config/tasks.json", strm_config_path: str = "config/strm_tasks.json"):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            config_path: åŒæ­¥ä»»åŠ¡é…ç½®æ–‡ä»¶è·¯å¾„
            strm_config_path: STRM ä»»åŠ¡é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = Path(config_path)
        self.strm_config_path = Path(strm_config_path)
        
        # ä»»åŠ¡å­˜å‚¨ï¼šä½¿ç”¨ä¸åŒçš„å­—å…¸åˆ†å¼€å­˜å‚¨
        self.tasks: Dict[str, SyncTask] = {}  # task_id -> SyncTask
        self.strm_tasks: Dict[str, StrmTask] = {}  # task_id -> StrmTask
        
        self.task_queue = queue.Queue()  # ä»»åŠ¡æ‰§è¡Œé˜Ÿåˆ—ï¼ˆå…ƒç»„ï¼š(system_key, task_id)ï¼‰
        self.scheduler = BackgroundScheduler()  # APScheduler åå°è°ƒåº¦å™¨
        self.consumer_thread: Optional[threading.Thread] = None
        self.is_running = False
        self.log_callback: Optional[Callable[[str], None]] = None
        self.task_context_callback: Optional[Callable[[Optional[str]], None]] = None  # ä»»åŠ¡ä¸Šä¸‹æ–‡å›è°ƒ
        self.task_progress: Dict[str, dict] = {}  # ä»»åŠ¡è¿›åº¦ç¼“å­˜: task_id -> progress_info
        self.task_stats: Dict[str, dict] = {}  # ä»»åŠ¡æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯: task_id -> stats
        
        # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆSQLiteï¼‰
        db_path = self.config_path.parent / "cloudgather.db"
        self.db = Database(str(db_path))
        
        # å‘åå…¼å®¹ï¼šä¿ç•™å†…å­˜é˜Ÿåˆ—ï¼ˆå·²åºŸå¼ƒï¼Œä»…ç”¨äºè¿ç§»ï¼‰
        self.delete_queue: List[dict] = []
        self._delete_queue_lock = threading.Lock()
        
        # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
        try:
            self.config_path.parent.mkdir(parents=True, exist_ok=True)
            self.strm_config_path.parent.mkdir(parents=True, exist_ok=True)
            if self.log_callback:
                self.log_callback(f"âœ“ é…ç½®ç›®å½•å·²åˆ›å»º: {self.config_path.parent}")
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºé…ç½®ç›®å½•å¤±è´¥: {e}")
        
        # ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œé¿å…å®¿ä¸»æœºæŒ‚è½½ç›®å½•æœªç”Ÿæˆæ–‡ä»¶
        self._ensure_config_file()
        self._ensure_strm_config_file()
        
        # è‡ªåŠ¨æ£€æµ‹å¹¶æ‰§è¡Œç¼“å­˜è¿ç§»
        self._auto_migrate_cache_if_needed()
        
        # åŠ è½½å·²ä¿å­˜çš„ä»»åŠ¡
        self.load_tasks()
        self.load_strm_tasks()
    
    def set_log_callback(self, callback: Callable[[str], None]):
        """
        è®¾ç½®æ—¥å¿—å›è°ƒå‡½æ•°
        
        Args:
            callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        self.log_callback = callback
    
    def set_task_context_callback(self, callback: Callable[[Optional[str]], None]):
        """
        è®¾ç½®ä»»åŠ¡ä¸Šä¸‹æ–‡å›è°ƒå‡½æ•°
        
        Args:
            callback: ä»»åŠ¡ä¸Šä¸‹æ–‡å›è°ƒå‡½æ•°ï¼Œå‚æ•°ä¸ºå½“å‰ä»»åŠ¡IDæˆ–None
        """
        self.task_context_callback = callback
    
    def _log(self, message: str):
        """
        è¾“å‡ºæ—¥å¿—
        
        Args:
            message: æ—¥å¿—æ¶ˆæ¯
        """
        if self.log_callback:
            self.log_callback(message)
    
    def _schedule_file_deletion(self, task: SyncTask, source_file: Path):
        """æ ¹æ®ä»»åŠ¡é…ç½®ä¸ºå•ä¸ªæ–‡ä»¶è®¡ç®—åˆ é™¤æ—¶é—´å¹¶åŠ å…¥é˜Ÿåˆ—"""
        # æœªå¼€å¯åˆ é™¤åˆ™ç›´æ¥è¿”å›
        if not getattr(task, "delete_source", False):
            return

        # å…è®¸ 0 å¤©è¡¨ç¤ºåŒæ­¥å®Œæˆåç«‹å³åˆ é™¤ï¼Œè´Ÿæ•°ä¸€å¾‹æŒ‰ 0 å¤„ç†
        delay_days = getattr(task, "delete_delay_days", None)
        if delay_days is None:
            delay_days = 0
        try:
            delay_days = int(delay_days)
        except (TypeError, ValueError):
            delay_days = 0
        if delay_days < 0:
            delay_days = 0

        base_type = (getattr(task, "delete_time_base", "SYNC_COMPLETE") or "SYNC_COMPLETE").upper()

        # è®¡ç®—åŸºå‡†æ—¶é—´
        try:
            if base_type == "FILE_CREATE":
                stat = source_file.stat()
                base_time = datetime.fromtimestamp(stat.st_ctime)
            else:
                # é»˜è®¤ä½¿ç”¨åŒæ­¥å®Œæˆæ—¶é—´ï¼ˆè¿‘ä¼¼ä¸ºå½“å‰æ—¶é—´ï¼‰
                base_time = datetime.now()
        except Exception as e:
            self._log(f"âš  è®¡ç®—åˆ é™¤æ—¶é—´å¤±è´¥: {source_file} - {e}")
            return

        delete_at = base_time + timedelta(days=delay_days)

        record = {
            "task_id": task.id,
            "source_path": str(source_file),
            "delete_at": delete_at.isoformat(),
            "delete_parent": bool(getattr(task, "delete_parent", False)),
            "time_base": base_type,
        }

        # å†™å…¥æ•°æ®åº“ï¼ˆæ›¿ä»£å†…å­˜é˜Ÿåˆ—ï¼‰
        try:
            self.db.add_delete_record(
                task_id=task.id,
                source_path=str(source_file),
                delete_at=delete_at.isoformat(),
                delete_parent=bool(getattr(task, "delete_parent", False)),
                time_base=base_type
            )
        except Exception as e:
            self._log(f"âš  æ·»åŠ åˆ é™¤è®°å½•å¤±è´¥: {source_file} - {e}")

    def _on_file_synced(self, task: SyncTask, source_file: Path, result: str):
        """å•ä¸ªæ–‡ä»¶åŒæ­¥å®Œæˆå›è°ƒï¼Œç”¨äºè°ƒåº¦åˆ é™¤å’Œæ›´æ–°ç¼“å­˜"""
        # æ›´æ–°ç¼“å­˜çŠ¶æ€
        status_map = {
            "Success": "SYNCED",
            "Skipped (Unchanged)": "SKIPPED",
            "Skipped (Filtered)": "SKIPPED",
            "Skipped (Ignored)": "SKIPPED",
            "Skipped (Active)": "PENDING",
            "Failed": "FAILED"
        }
        
        sync_status = status_map.get(result, "PENDING")
        error_msg = None if sync_status != "FAILED" else result
        
        try:
            stat = source_file.stat()
            self.db.upsert_file_cache(
                task_id=task.id,
                path=str(source_file),
                size=stat.st_size,
                mtime=stat.st_mtime,
                sync_status=sync_status,
                synced_at=datetime.now().isoformat() if sync_status in ("SYNCED", "SKIPPED") else None,
                last_error=error_msg
            )
            
            # æ·»åŠ å†å²è®°å½•ï¼ˆå¸¦å»é‡ï¼‰
            self.db.add_history_record(
                task_id=task.id,
                path=str(source_file),
                status=sync_status,
                details=result if sync_status == "FAILED" else None
            )
        except Exception as e:
            self._log(f"âš  æ›´æ–°æ–‡ä»¶ç¼“å­˜å¤±è´¥: {source_file} - {e}")

        # è°ƒåº¦åˆ é™¤
        if result in ("Success", "Skipped (Unchanged)"):
            self._schedule_file_deletion(task, source_file)

    def _process_delete_queue_for_task(self, task: SyncTask):
        """æ‰«æåˆ é™¤é˜Ÿåˆ—ä¸­å±äºæŒ‡å®šä»»åŠ¡ä¸”åˆ°æœŸçš„è®°å½•ï¼Œå¹¶æ‰§è¡Œåˆ é™¤"""
        now = datetime.now()
        task_id = task.id
        task_source_root = Path(task.source_path)

        # ä»æ•°æ®åº“è·å–åˆ°æœŸè®°å½•
        try:
            expired_records = self.db.get_expired_records(task_id, now.isoformat())
        except Exception as e:
            self._log(f"âš  è·å–åˆ é™¤é˜Ÿåˆ—å¤±è´¥: {e}")
            return

        # åˆ é™¤ç»Ÿè®¡
        delete_stats = {
            "files_deleted": 0,
            "dirs_deleted": 0,
            "files_not_exist": 0,
            "files_failed": 0
        }
        # æœ¬è½®æˆåŠŸåˆ é™¤çš„æºæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç”¨äºåç»­ç›®å½•æ¸…ç†ï¼‰
        deleted_files: List[Path] = []
        deleted_record_ids: List[int] = []  # å·²å¤„ç†çš„è®°å½•ID
        
        for record in expired_records:
            record_id = record.get("id")
            source_path = record.get("source_path")
            delete_parent = bool(record.get("delete_parent", False))

            if not source_path:
                continue

            path = Path(source_path)
            try:
                # å®‰å…¨æ€§å¢å¼ºï¼šéªŒè¯åŒæ­¥è®°å½•
                if not self.db.is_file_synced(task_id, source_path):
                    self._log(f"ğŸ›¡ å®‰å…¨æ‹¦æˆªï¼šæ–‡ä»¶æœªç¡®è®¤åŒæ­¥ï¼Œæ‹’ç»åˆ é™¤: {path}")
                    # ä¸ç§»é™¤è®°å½•ï¼Œæ ‡è®°ä¸ºå¤±è´¥ä»¥ä¾¿åç»­é‡è¯•æˆ–äººå·¥æ£€æŸ¥
                    delete_stats["files_failed"] += 1
                    continue

                if path.exists():
                    try:
                        path.unlink()
                        delete_stats["files_deleted"] += 1
                        deleted_files.append(path)
                        deleted_record_ids.append(record_id)
                        
                        # æ›´æ–°ç¼“å­˜æ ‘ä¸­çš„åˆ é™¤æ—¶é—´
                        self.db.update_sync_status(
                            task_id=task_id,
                            path=source_path,
                            status="DELETED",
                            deleted_at=datetime.now().isoformat()
                        )
                        
                        # æ·»åŠ å†å²è®°å½•ï¼ˆå¸¦å»é‡ï¼‰
                        self.db.add_history_record(
                            task_id=task_id,
                            path=source_path,
                            status="DELETED"
                        )
                        
                        self._log(f"ğŸ—‘ å·²åˆ é™¤æºæ–‡ä»¶: {path}")
                    except IsADirectoryError:
                        # æç«¯æƒ…å†µï¼šè®°å½•çš„æ˜¯ç›®å½•
                        if path.is_dir():
                            shutil.rmtree(path, ignore_errors=False)
                            delete_stats["dirs_deleted"] += 1
                            deleted_files.append(path)
                            deleted_record_ids.append(record_id)
                            self._log(f"ğŸ—‘ å·²åˆ é™¤ç›®å½•: {path}")
                else:
                    delete_stats["files_not_exist"] += 1
                    deleted_record_ids.append(record_id)  # æ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿä»é˜Ÿåˆ—ä¸­ç§»é™¤
                    self._log(f"â„¹ æºæ–‡ä»¶å·²ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")
            except Exception as e:
                delete_stats["files_failed"] += 1
                self._log(f"âš  åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {path} - {e}")
                # åˆ é™¤å¤±è´¥ä¸ç§»é™¤è®°å½•ï¼Œä¸‹æ¬¡é‡è¯•
                continue

        # ä»æ•°æ®åº“ä¸­ç§»é™¤å·²å¤„ç†çš„è®°å½•
        try:
            self.db.remove_delete_records_by_id(deleted_record_ids)
        except Exception as e:
            self._log(f"âš  æ¸…ç†åˆ é™¤è®°å½•å¤±è´¥: {e}")
        
        # åŸºäºæœ¬è½®æˆåŠŸåˆ é™¤çš„æ–‡ä»¶ï¼ŒæŒ‰ä»»åŠ¡é…ç½®æ¸…ç†ä¸Šçº§ç›®å½•
        try:
            self._cleanup_parent_dirs_for_deleted(task, deleted_files, delete_stats, now)
        except Exception as e:
            self._log(f"âš  å¤„ç†ä¸Šçº§ç›®å½•åˆ é™¤æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        
        # è¾“å‡ºåˆ é™¤ç»Ÿè®¡æ±‡æ€»
        total_deleted = delete_stats["files_deleted"] + delete_stats["dirs_deleted"]
        if total_deleted > 0 or delete_stats["files_not_exist"] > 0 or delete_stats["files_failed"] > 0:
            self._log(
                f"âœ… åˆ é™¤é˜Ÿåˆ—å¤„ç†å®Œæˆ: "
                f"åˆ é™¤æ–‡ä»¶ {delete_stats['files_deleted']} ä¸ª, "
                f"åˆ é™¤ç›®å½• {delete_stats['dirs_deleted']} ä¸ª, "
                f"å·²ä¸å­˜åœ¨ {delete_stats['files_not_exist']} ä¸ª, "
                f"åˆ é™¤å¤±è´¥ {delete_stats['files_failed']} ä¸ª"
            )

    def _cleanup_parent_dirs_for_deleted(self, task: SyncTask, deleted_files: List[Path], delete_stats: dict, now: datetime):
        """æ ¹æ®ä»»åŠ¡é…ç½®ï¼Œä¸ºæœ¬è½®å·²åˆ é™¤çš„æ–‡ä»¶å‘ä¸Šå°è¯•åˆ é™¤ä¸Šçº§ç›®å½•"""
        # æœªå¯ç”¨ç›®å½•åˆ é™¤ï¼Œç›´æ¥è¿”å›
        if not getattr(task, "delete_parent", False):
            return
        if not deleted_files:
            return

        # è§£æä»»åŠ¡æºç›®å½•ä¸å…³é”®è·¯å¾„
        try:
            root = Path(task.source_path)
            try:
                root_resolved = root.resolve()
            except Exception:
                root_resolved = root
        except Exception:
            return

        home_dir = Path.home()
        try:
            home_resolved = home_dir.resolve()
        except Exception:
            home_resolved = home_dir

        max_levels = 0
        try:
            max_levels = int(getattr(task, "delete_parent_levels", 0) or 0)
        except (TypeError, ValueError):
            max_levels = 0
        if max_levels <= 0:
            return

        # æ˜¯å¦å¼ºåˆ¶åˆ é™¤éç©ºç›®å½•ï¼ˆä»ç„¶ä¼šä¿æŠ¤æœªåˆ°æœŸæ–‡ä»¶ï¼‰
        force_delete_nonempty = bool(getattr(task, "delete_parent_force", False))

        processed_dirs: Set[Path] = set()

        for file_path in deleted_files:
            # åªå¤„ç†æºç›®å½•å­æ ‘å†…çš„æ–‡ä»¶
            try:
                fp = Path(file_path)
            except Exception:
                continue

            parent = fp.parent
            level = 1

            while level <= max_levels:
                cand = parent
                if cand in processed_dirs:
                    # å·²å¤„ç†è¿‡çš„ç›®å½•ä¸å¿…é‡å¤
                    break

                if not cand.exists():
                    break

                try:
                    cand_resolved = cand.resolve()
                except Exception:
                    cand_resolved = cand

                # æ ¹ç›®å½• / ç”¨æˆ·ä¸»ç›®å½• / ä»»åŠ¡æºç›®å½•æœ¬èº« ç¦æ­¢åˆ é™¤
                root_of_drive = Path(cand_resolved.anchor) if cand_resolved.anchor else None
                if (root_of_drive is not None and cand_resolved == root_of_drive) or cand_resolved == home_resolved:
                    break
                if cand_resolved == root_resolved:
                    # ä¸åˆ é™¤ source_path æœ¬èº«ï¼Œåœæ­¢å‘ä¸Šæ£€æŸ¥
                    break

                # cand å¿…é¡»åœ¨ä»»åŠ¡æºç›®å½•å­æ ‘å†…
                if root_resolved not in cand_resolved.parents:
                    break

                # è‹¥ç›®å½•ä¸‹è¿˜æœ‰æœªåˆ°åˆ é™¤æ—¶é—´çš„æ–‡ä»¶ï¼Œåˆ™æš‚ç¼“åˆ é™¤
                if self._has_pending_delete_entries(task_id=task.id, base_dir=cand_resolved, queue_snapshot=[], now=now):
                    break

                # éå¼ºåˆ¶æ¨¡å¼ä¸‹ï¼Œä»…åœ¨ç›®å½•ç‰©ç†ä¸ºç©ºæ—¶åˆ é™¤
                if not force_delete_nonempty:
                    try:
                        if any(cand.iterdir()):
                            break
                    except Exception:
                        break

                # å®‰å…¨åˆ é™¤è¯¥ç›®å½•
                try:
                    shutil.rmtree(cand, ignore_errors=False)
                    delete_stats["dirs_deleted"] += 1
                    self._log(f"ğŸ—‘ å·²åˆ é™¤ä¸Šçº§ç›®å½•: {cand}")
                except Exception as e:
                    self._log(f"âš  åˆ é™¤ä¸Šçº§ç›®å½•å¤±è´¥: {cand} - {e}")
                    break

                processed_dirs.add(cand)
                # ç»§ç»­å‘ä¸Šå°è¯•
                parent = cand.parent
                level += 1

    def _has_pending_delete_entries(self, task_id: str, base_dir: Path, queue_snapshot: List[dict], now: datetime) -> bool:
        """åˆ¤æ–­æŒ‡å®šç›®å½•å­æ ‘ä¸‹æ˜¯å¦å­˜åœ¨æœªåˆ°åˆ é™¤æ—¶é—´çš„è®°å½•"""
        # ä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢
        try:
            pending_records = self.db.get_pending_records(
                task_id=task_id,
                current_time=now.isoformat(),
                base_dir=str(base_dir)
            )
            return len(pending_records) > 0
        except Exception as e:
            self._log(f"âš  æŸ¥è¯¢æœªåˆ°æœŸè®°å½•å¤±è´¥: {e}")
            # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ï¼Œè¿”å› True é¿å…è¯¯åˆ 
            return True

    def _update_progress(self, task_id: str, stats: dict):
        """
            task_id: ä»»åŠ¡ID
            stats: åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        done = stats["success"] + stats["skipped_ignored"] + stats["skipped_active"] + stats["skipped_unchanged"] + stats.get("skipped_filtered", 0) + stats["failed"]
        total = stats["total"]
        percent = (done / total * 100) if total > 0 else 0
        
        self.task_progress[task_id] = {
            "done": done,
            "total": total,
            "success": stats["success"],
            "skipped": stats["skipped_ignored"] + stats["skipped_active"] + stats["skipped_unchanged"] + stats.get("skipped_filtered", 0),
            "failed": stats["failed"],
            "percent": round(percent, 1)
        }
    
    def _auto_migrate_cache_if_needed(self):
        """è‡ªåŠ¨æ£€æµ‹å¹¶æ‰§è¡Œç¼“å­˜è¿ç§»ï¼ˆResult-driven Reconstructionï¼‰
        åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶æ£€æµ‹ç¼“å­˜è¡¨æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™è‡ªåŠ¨æ‰§è¡Œè¿ç§»
        """
        try:
            # æ£€æŸ¥ç¼“å­˜è¡¨æ˜¯å¦ä¸ºç©º
            cache_count = self.db.get_cache_count()
            task_count = len(self.tasks) + len(self.strm_tasks)
            
            self._log(f"ğŸ” ç¼“å­˜è‡ªåŠ¨è¿ç§»æ£€æŸ¥: ç¼“å­˜è®°å½•={cache_count}, ä»»åŠ¡æ€»æ•°={task_count}")
            
            # å¦‚æœç¼“å­˜ä¸ºç©ºä½†å­˜åœ¨ä»»åŠ¡ï¼Œåˆ™è‡ªåŠ¨æ‰§è¡Œè¿ç§»
            if cache_count == 0 and task_count > 0:
                self._log("ğŸ”„ æ£€æµ‹åˆ°ç¼“å­˜ä¸ºç©ºï¼Œè‡ªåŠ¨å¯åŠ¨ç¼“å­˜è¿ç§»...")
                
                # ä¸ºæ¯ä¸ªåŒæ­¥ä»»åŠ¡æ‰§è¡Œé‡æ„
                for task in self.tasks.values():
                    try:
                        self._log(f"ğŸ›  è‡ªåŠ¨é‡æ„åŒæ­¥ä»»åŠ¡ç¼“å­˜: {task.name}")
                        syncer = FileSyncer(
                            source_dir=task.source_path,
                            target_dir=task.target_path,
                            task_id=task.id,
                            db=self.db
                        )
                        stats = syncer.reconstruct_cache_from_target(log_callback=self._log)
                        self._log(f"âœ… åŒæ­¥ä»»åŠ¡ '{task.name}' ç¼“å­˜é‡æ„å®Œæˆ: æ‰«æ{stats['found']}, åŒ¹é…{stats['matched']}, æ›´æ–°{stats['updated']}")
                    except Exception as e:
                        self._log(f"âŒ åŒæ­¥ä»»åŠ¡ '{task.name}' ç¼“å­˜é‡æ„å¤±è´¥: {e}")
                
                # ä¸ºæ¯ä¸ªSTRMä»»åŠ¡æ‰§è¡Œé‡æ„
                for task in self.strm_tasks.values():
                    try:
                        self._log(f"ğŸ›  è‡ªåŠ¨é‡æ„STRMä»»åŠ¡ç¼“å­˜: {task.name}")
                        from core.strm_generator import StrmGenerator
                        generator = StrmGenerator(task, self._log, self.db)
                        stats = generator.reconstruct_cache_from_target(log_callback=self._log)
                        self._log(f"âœ… STRMä»»åŠ¡ '{task.name}' ç¼“å­˜é‡æ„å®Œæˆ: æ‰«æ{stats['found']}, åŒ¹é…{stats['matched']}, æ›´æ–°{stats['updated']}")
                    except Exception as e:
                        self._log(f"âŒ STRMä»»åŠ¡ '{task.name}' ç¼“å­˜é‡æ„å¤±è´¥: {e}")
                
                # å†æ¬¡æ£€æŸ¥ç¼“å­˜æ•°é‡
                final_count = self.db.get_cache_count()
                self._log(f"âœ… ç¼“å­˜è‡ªåŠ¨è¿ç§»å®Œæˆ! æ–°å¢ç¼“å­˜è®°å½•: {final_count}")
            elif cache_count > 0:
                self._log(f"âœ… ç¼“å­˜å·²å­˜åœ¨ ({cache_count} æ¡è®°å½•)ï¼Œè·³è¿‡è‡ªåŠ¨è¿ç§»")
            else:
                self._log("â„¹ï¸ æ— ä»»åŠ¡é…ç½®ï¼Œæ— éœ€æ‰§è¡Œç¼“å­˜è¿ç§»")
                
        except Exception as e:
            self._log(f"âš  ç¼“å­˜è‡ªåŠ¨è¿ç§»æ£€æŸ¥å¤±è´¥: {e}")

    def _ensure_config_file(self):
        """ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œè‹¥ç¼ºå¤±åˆ™åˆ›å»ºç©ºæ–‡ä»¶"""
        try:
            self.config_path.parent.mkdir(parents=True, exist_ok=True)
            if not self.config_path.exists():
                data = {
                    "schema_version": CONFIG_SCHEMA_VERSION,
                    "tasks": [],
                    "last_saved": datetime.now().isoformat(),
                    "delete_queue": []
                }
                self.config_path.write_text(
                    json.dumps(data, indent=2, ensure_ascii=False),
                    encoding='utf-8'
                )
        except Exception as e:
            # ä½¿ç”¨ print ä¿è¯å¯åŠ¨é˜¶æ®µä¹Ÿèƒ½çœ‹åˆ°
            print(f"âš ï¸ æ— æ³•åˆ›å»ºé…ç½®æ–‡ä»¶ {self.config_path}: {e}")
            if self.log_callback:
                self.log_callback(f"âš ï¸ æ— æ³•åˆ›å»ºé…ç½®æ–‡ä»¶: {self.config_path} - {e}")
    
    def _ensure_strm_config_file(self):
        """ç¡®ä¿ STRM ä»»åŠ¡é…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œè‹¥ç¼ºå¤±åˆ™åˆ›å»ºç©ºæ–‡ä»¶"""
        try:
            self.strm_config_path.parent.mkdir(parents=True, exist_ok=True)
            if not self.strm_config_path.exists():
                data = {
                    "schema_version": CONFIG_SCHEMA_VERSION,
                    "tasks": [],
                    "last_saved": datetime.now().isoformat()
                }
                self.strm_config_path.write_text(
                    json.dumps(data, indent=2, ensure_ascii=False),
                    encoding='utf-8'
                )
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åˆ›å»º STRM é…ç½®æ–‡ä»¶ {self.strm_config_path}: {e}")
            if self.log_callback:
                self.log_callback(f"âš ï¸ æ— æ³•åˆ›å»º STRM é…ç½®æ–‡ä»¶: {self.strm_config_path} - {e}")
    
    def _validate_task_paths(self, task: SyncTask) -> bool:
        """æ£€æŸ¥ä»»åŠ¡çš„æº/ç›®æ ‡ç›®å½•å¯ç”¨æ€§ï¼Œå¹¶åœ¨éœ€è¦æ—¶åˆ›å»ºç›®æ ‡ç›®å½•"""
        try:
            source = Path(task.source_path)
            target = Path(task.target_path)
            
            if not source.exists():
                self._log(f"âœ— æºç›®å½•ä¸å­˜åœ¨: {source}")
                return False
            if not source.is_dir():
                self._log(f"âœ— æºè·¯å¾„ä¸æ˜¯ç›®å½•: {source}")
                return False
            if not os.access(source, os.R_OK):
                self._log(f"âœ— æ²¡æœ‰è¯»å–æºç›®å½•çš„æƒé™: {source}")
                return False
            
            if not target.exists():
                target.mkdir(parents=True, exist_ok=True)
                self._log(f"ğŸ“ å·²åˆ›å»ºç›®æ ‡ç›®å½•: {target}")
            if not target.is_dir():
                self._log(f"âœ— ç›®æ ‡è·¯å¾„ä¸æ˜¯ç›®å½•: {target}")
                return False
            if not os.access(target, os.W_OK):
                self._log(f"âœ— æ²¡æœ‰å†™å…¥ç›®æ ‡ç›®å½•çš„æƒé™: {target}")
                return False
            
            return True
        except PermissionError as e:
            self._log(f"âœ— ç›®å½•æƒé™ä¸è¶³: {e}")
            return False
        except Exception as e:
            self._log(f"âœ— ç›®å½•æ£€æŸ¥å¤±è´¥: {e}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    def add_task(self, task: SyncTask) -> bool:
        """
        æ·»åŠ ä»»åŠ¡åˆ°è°ƒåº¦å™¨
        
        Args:
            task: åŒæ­¥ä»»åŠ¡å¯¹è±¡
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            if task.id in self.tasks:
                self._log(f"ä»»åŠ¡å·²å­˜åœ¨: {task.name} ({task.id})")
                return False
            
            # æ·»åŠ åˆ°ä»»åŠ¡å­—å…¸
            self.tasks[task.id] = task
            
            # å¦‚æœä»»åŠ¡å¯ç”¨ä¸”è°ƒåº¦å™¨å·²è¿è¡Œï¼Œåˆ™æ·»åŠ å®šæ—¶ä»»åŠ¡
            if task.enabled and self.is_running:
                self._schedule_task(task)
            
            # ä¿å­˜é…ç½®
            self.save_tasks()
            
            self._log(f"âœ“ ä»»åŠ¡æ·»åŠ å®Œæˆ: {task.name}")
            return True
            
        except Exception as e:
            self._log(f"âœ— æ·»åŠ ä»»åŠ¡å¤±è´¥: {task.name} - {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    def remove_task(self, task_id: str) -> bool:
        """
        ç§»é™¤ä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦ç§»é™¤æˆåŠŸ
        """
        try:
            if task_id not in self.tasks:
                self._log(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return False
            
            task = self.tasks[task_id]
            
            # ä»è°ƒåº¦å™¨ä¸­ç§»é™¤
            if self.scheduler.get_job(task_id):
                self.scheduler.remove_job(task_id)
            
            # ä»ä»»åŠ¡å­—å…¸ä¸­ç§»é™¤
            del self.tasks[task_id]
            
            # ä¿å­˜é…ç½®
            self.save_tasks()
            
            self._log(f"âœ“ ä»»åŠ¡å·²ç§»é™¤: {task.name}")
            return True
            
        except Exception as e:
            self._log(f"âœ— ç§»é™¤ä»»åŠ¡å¤±è´¥: {task_id} - {str(e)}")
            return False
    
    def update_task(self, task_id: str, **kwargs) -> bool:
        """
        æ›´æ–°ä»»åŠ¡é…ç½®
        
        Args:
            task_id: ä»»åŠ¡ID
            **kwargs: è¦æ›´æ–°çš„å­—æ®µ
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            if task_id not in self.tasks:
                self._log(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return False
            
            task = self.tasks[task_id]
            old_interval = task.interval
            old_enabled = task.enabled
            
            # æ›´æ–°å­—æ®µ
            for key, value in kwargs.items():
                if hasattr(task, key):
                    setattr(task, key, value)
            
            # å¦‚æœé—´éš”æˆ–å¯ç”¨çŠ¶æ€æ”¹å˜ï¼Œé‡æ–°è°ƒåº¦
            if (task.interval != old_interval or task.enabled != old_enabled) and self.is_running:
                if self.scheduler.get_job(task_id):
                    self.scheduler.remove_job(task_id)
                
                if task.enabled:
                    self._schedule_task(task)
            
            # ä¿å­˜é…ç½®
            self.save_tasks()
            
            self._log(f"âœ“ ä»»åŠ¡å·²æ›´æ–°: {task.name}")
            return True
            
        except Exception as e:
            self._log(f"âœ— æ›´æ–°ä»»åŠ¡å¤±è´¥: {task_id} - {str(e)}")
            return False
    
    def get_task(self, task_id: str) -> Optional[SyncTask]:
        """
        è·å–ä»»åŠ¡å¯¹è±¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            ä»»åŠ¡å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å› None
        """
        return self.tasks.get(task_id)
    
    def get_all_tasks(self) -> List[SyncTask]:
        """
        è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨
        
        Returns:
            ä»»åŠ¡åˆ—è¡¨
        """
        return list(self.tasks.values())
    
    def _schedule_task(self, task, system_key='sync'):
        """
        å°†ä»»åŠ¡æ·»åŠ åˆ° APSchedulerï¼ˆæ”¯æŒå¤šä»»åŠ¡ç³»ç»Ÿï¼‰
        
        Args:
            task: ä»»åŠ¡å¯¹è±¡ï¼ˆSyncTask æˆ– StrmTaskï¼‰
            system_key: ç³»ç»Ÿæ ‡è¯†ï¼ˆ'sync' æˆ– 'strm'ï¼‰
        """
        # æ ¹æ®è°ƒåº¦ç±»å‹é€‰æ‹©ä¸åŒçš„ trigger
        if task.schedule_type == ScheduleType.CRON:
            # Cron è¡¨è¾¾å¼è°ƒåº¦
            if not task.cron_expression:
                self._log(f"âš  ä»»åŠ¡ {task.name} çš„ Cron è¡¨è¾¾å¼ä¸ºç©ºï¼Œè·³è¿‡è°ƒåº¦")
                return
            try:
                # è§£æ cron è¡¨è¾¾å¼ï¼šåˆ† æ—¶ æ—¥ æœˆ æ˜ŸæœŸ
                parts = task.cron_expression.strip().split()
                if len(parts) == 5:
                    minute, hour, day, month, day_of_week = parts
                    trigger = CronTrigger(
                        minute=minute,
                        hour=hour,
                        day=day,
                        month=month,
                        day_of_week=day_of_week
                    )
                    self._log(f"ä»»åŠ¡å·²è°ƒåº¦ (Cron): {task.name} ({task.cron_expression})")
                else:
                    self._log(f"âš  ä»»åŠ¡ {task.name} çš„ Cron è¡¨è¾¾å¼æ ¼å¼é”™è¯¯: {task.cron_expression}")
                    return
            except Exception as e:
                self._log(f"âš  è§£æ Cron è¡¨è¾¾å¼å¤±è´¥: {task.name} - {str(e)}")
                return
        else:
            # é—´éš”è°ƒåº¦ï¼ˆé»˜è®¤ï¼‰
            trigger = IntervalTrigger(seconds=task.interval)
            self._log(f"ä»»åŠ¡å·²è°ƒåº¦ (Interval): {task.name} (é—´éš”: {task.interval}s)")
        
        # å…³é”®æ”¹é€ ï¼šä½¿ç”¨ system_key å‰ç¼€
        job_id = f"{system_key}_{task.id}"
        
        self.scheduler.add_job(
            func=self._on_task_triggered,
            trigger=trigger,
            id=job_id,  # ä½¿ç”¨å‰ç¼€åçš„ job_id
            args=[task.id, system_key],  # ä¼ é€’ system_key
            replace_existing=True
        )
    
    def _on_task_triggered(self, task_id: str, system_key: str = 'sync'):
        """
        å®šæ—¶å™¨è§¦å‘å›è°ƒï¼šå°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—ï¼ˆæ”¯æŒå¤šä»»åŠ¡ç³»ç»Ÿï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
            system_key: ç³»ç»Ÿæ ‡è¯†ï¼ˆ'sync' æˆ– 'strm'ï¼‰
        """
        # æ ¹æ® system_key è·¯ç”±åˆ°ä¸åŒçš„ä»»åŠ¡å­—å…¸
        if system_key == 'sync':
            if task_id not in self.tasks:
                return
            task = self.tasks[task_id]
        elif system_key == 'strm':
            if task_id not in self.strm_tasks:
                return
            task = self.strm_tasks[task_id]
        else:
            self._log(f"âš  æœªçŸ¥çš„ä»»åŠ¡ç³»ç»Ÿ: {system_key}")
            return
        
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼Œé¿å…é‡å¤å…¥é˜Ÿ
        if task.status == TaskStatus.IDLE:
            # æ›´æ–°çŠ¶æ€ä¸º QUEUED
            task.update_status(TaskStatus.QUEUED)
            
            # å°†ä»»åŠ¡ä¿¡æ¯æ”¾å…¥é˜Ÿåˆ—ï¼ˆå…ƒç»„ï¼š(system_key, task_id)ï¼‰
            self.task_queue.put((system_key, task_id))
            
            self._log(f"â± ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—: {task.name} [{system_key}]")
        else:
            self._log(f"âš  ä»»åŠ¡ä»åœ¨æ‰§è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒåº¦: {task.name} (çŠ¶æ€: {task.status.value})")
    
    def _task_consumer(self):
        """
        åå°ä»»åŠ¡çº¿ç¨‹ï¼šä»é˜Ÿåˆ—å–å‡ºä»»åŠ¡å¹¶æ‰§è¡Œï¼ˆæ”¯æŒå¤šä»»åŠ¡ç³»ç»Ÿï¼‰
        """
        self._log("ğŸ“Œ ä»»åŠ¡çº¿ç¨‹å·²å¯åŠ¨")
        
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—å–å‡ºä»»åŠ¡ä¿¡æ¯ï¼ˆè¶…æ—¶1ç§’ï¼Œé¿å…é˜»å¡å…³é—­ï¼‰
                try:
                    queue_item = self.task_queue.get(timeout=1)
                except queue.Empty:
                    continue
                
                # è§£æé˜Ÿåˆ—é¡¹ï¼š(system_key, task_id)
                if isinstance(queue_item, tuple) and len(queue_item) == 2:
                    system_key, task_id = queue_item
                else:
                    # å‘åå…¼å®¹ï¼šæ—§ç‰ˆæœ¬åªæœ‰ task_id
                    system_key = 'sync'
                    task_id = queue_item
                
                # æ ¹æ® system_key è·¯ç”±åˆ°ä¸åŒçš„ä»»åŠ¡ç³»ç»Ÿ
                if system_key == 'sync':
                    if task_id not in self.tasks:
                        self._log(f"âš  åŒæ­¥ä»»åŠ¡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {task_id}")
                        self.task_queue.task_done()
                        continue
                    task = self.tasks[task_id]
                    self._execute_sync_task(task)
                    
                elif system_key == 'strm':
                    if task_id not in self.strm_tasks:
                        self._log(f"âš  STRM ä»»åŠ¡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {task_id}")
                        self.task_queue.task_done()
                        continue
                    task = self.strm_tasks[task_id]
                    self._execute_strm_task(task)
                    
                else:
                    self._log(f"âš  æœªçŸ¥çš„ä»»åŠ¡ç³»ç»Ÿ: {system_key}")
                    self.task_queue.task_done()
                    continue
                
            except Exception as e:
                self._log(f"ä»»åŠ¡çº¿ç¨‹å¼‚å¸¸: {str(e)}")
                import traceback
                self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        self._log("ğŸ“Œ ä»»åŠ¡çº¿ç¨‹å·²åœæ­¢")
    
    def _execute_sync_task(self, task: SyncTask):
        """æ‰§è¡ŒåŒæ­¥ä»»åŠ¡ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        task_id = task.id
        
        # åœ¨æ‰§è¡ŒåŒæ­¥å‰å¤„ç†è¯¥ä»»åŠ¡å·²åˆ°æœŸçš„åˆ é™¤é˜Ÿåˆ—
        try:
            self._process_delete_queue_for_task(task)
        except Exception as e:
            self._log(f"âš  å¤„ç†åˆ é™¤é˜Ÿåˆ—å¤±è´¥: {task.name} - {e}")
        
        # è®¾ç½®å½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡
        if self.task_context_callback:
            self.task_context_callback(task_id)
        
        # æ›´æ–°çŠ¶æ€ä¸º RUNNING
        task.update_status(TaskStatus.RUNNING)
        self._log(f"â–¶ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.name}")
        
        # è¿è¡Œå‰æ ¡éªŒè·¯å¾„ï¼Œå¹¶åœ¨ç›®æ ‡ç¼ºå¤±æ—¶å°è¯•åˆ›å»º
        if not self._validate_task_paths(task):
            task.update_status(TaskStatus.ERROR)
            self._log(f"âœ— è·¯å¾„æ£€æŸ¥å¤±è´¥ï¼Œä»»åŠ¡ç»ˆæ­¢: {task.name}")
            if self.task_context_callback:
                self.task_context_callback(None)
            self.task_queue.task_done()
            self.save_tasks()
            return
        
        # æ‰§è¡ŒåŒæ­¥
        try:
            syncer = FileSyncer(
                source_dir=task.source_path,
                target_dir=task.target_path,
                task_id=task_id,
                db=self.db
            )
            
            # è·å–ç³»ç»Ÿé‡è¯•è®¾ç½®
            from api.settings import load_system_config
            system_config = load_system_config()
            retry_count = system_config.get('sync_retry_count', 3)
            
            stats = syncer.sync_directory(
                overwrite_existing=task.overwrite_existing,
                rule_not_exists=task.rule_not_exists,
                rule_size_diff=task.rule_size_diff,
                rule_mtime_newer=task.rule_mtime_newer,
                thread_count=task.thread_count,
                log_callback=self._log,
                progress_callback=lambda s: self._update_progress(task_id, s),
                is_slow_storage=task.is_slow_storage,
                size_min_bytes=task.size_min_bytes,
                size_max_bytes=task.size_max_bytes,
                suffix_mode=task.suffix_mode,
                suffix_list=task.suffix_list,
                file_result_callback=lambda src, dst, result: self._on_file_synced(task, src, result),
                retry_count=retry_count
            )
            
            # åŒæ­¥å®Œæˆåå†æ¬¡å¤„ç†è¯¥ä»»åŠ¡åˆ é™¤é˜Ÿåˆ—ï¼ˆç¡®ä¿å»¶è¿Ÿä¸º 0 çš„è®°å½•ç«‹å³æ‰§è¡Œï¼‰
            try:
                self._process_delete_queue_for_task(task)
            except Exception as e:
                self._log(f"âš  åŒæ­¥å®Œæˆåå¤„ç†åˆ é™¤é˜Ÿåˆ—å¤±è´¥: {task.name} - {e}")
            
            # æ›´æ–°çŠ¶æ€ä¸º IDLE
            task.update_status(TaskStatus.IDLE)
            task.update_last_run_time()
            
            # ä¿å­˜æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
            total_skipped = stats['skipped_ignored'] + stats['skipped_active'] + stats['skipped_unchanged'] + stats.get('skipped_filtered', 0)
            self.task_stats[task_id] = {
                "total": stats['total'],
                "success": stats['success'],
                "skipped": total_skipped,
                "failed": stats['failed'],
                "skipped_filtered": stats.get('skipped_filtered', 0)
            }
            
            self._log(
                f"âœ“ ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task.name} "
                f"(æ€»æ–‡ä»¶æ•°: {stats['total']} "
                f"æˆåŠŸ: {stats['success']} "
                f"è·³è¿‡: {total_skipped} "
                f"å¤±è´¥: {stats['failed']})"
            )
            
        except Exception as e:
            # æ›´æ–°çŠ¶æ€ä¸º ERROR
            task.update_status(TaskStatus.ERROR)
            self._log(f"âœ— ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.name} - {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        finally:
            # æ¸…é™¤ä»»åŠ¡è¿›åº¦ç¼“å­˜
            self.task_progress.pop(task_id, None)
            
            # æ¸…é™¤ä»»åŠ¡ä¸Šä¸‹æ–‡
            if self.task_context_callback:
                self.task_context_callback(None)
            
            # æ ‡è®°ä»»åŠ¡å®Œæˆ
            self.task_queue.task_done()
            
            # ä¿å­˜ä»»åŠ¡çŠ¶æ€
            self.save_tasks()
    
    def _execute_strm_task(self, task: StrmTask):
        """æ‰§è¡Œ STRM ä»»åŠ¡"""
        task_id = task.id
        
        # è®¾ç½®å½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡
        if self.task_context_callback:
            self.task_context_callback(task_id)
        
        # æ›´æ–°çŠ¶æ€ä¸º RUNNING
        task.update_status(TaskStatus.RUNNING)
        self._log(f"â–¶ å¼€å§‹æ‰§è¡Œ STRM ä»»åŠ¡: {task.name}")
        
        # æ‰§è¡Œ STRM ç”Ÿæˆ
        try:
            from core.strm_generator import StrmGenerator
            
            generator = StrmGenerator(
                task=task,
                log_callback=self._log,
                db=self.db
            )
            
            stats = generator.run(
                progress_callback=lambda s: self._update_progress(task_id, s)
            )
            
            # æ›´æ–°çŠ¶æ€ä¸º IDLE
            task.update_status(TaskStatus.IDLE)
            task.update_last_run_time()
            
            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
            self.task_stats[task_id] = stats
            
            self._log(
                f"âœ“ STRM ä»»åŠ¡å®Œæˆ: {task.name} "
                f"(æ€»è®¡: {stats['total']} "
                f"æˆåŠŸ: {stats['success']} "
                f"è·³è¿‡: {stats['skipped']} "
                f"å¤±è´¥: {stats['failed']})"
            )
            
        except Exception as e:
            # æ›´æ–°çŠ¶æ€ä¸º ERROR
            task.update_status(TaskStatus.ERROR)
            self._log(f"âœ— STRM ä»»åŠ¡å¤±è´¥: {task.name} - {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        finally:
            # æ¸…é™¤ä»»åŠ¡è¿›åº¦ç¼“å­˜
            self.task_progress.pop(task_id, None)
            
            # æ¸…é™¤ä»»åŠ¡ä¸Šä¸‹æ–‡
            if self.task_context_callback:
                self.task_context_callback(None)
            
            # æ ‡è®°ä»»åŠ¡å®Œæˆ
            self.task_queue.task_done()
            
            # ä¿å­˜ä»»åŠ¡çŠ¶æ€
            self.save_strm_tasks()
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨å’Œä»»åŠ¡çº¿ç¨‹ï¼ˆæ”¯æŒå¤šä»»åŠ¡ç³»ç»Ÿï¼‰"""
        if self.is_running:
            self._log("âš  è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
            return
        
        self.is_running = True
        
        # ä¸ºæ‰€æœ‰å¯ç”¨çš„åŒæ­¥ä»»åŠ¡æ·»åŠ è°ƒåº¦
        for task in self.tasks.values():
            if task.enabled:
                self._schedule_task(task, system_key='sync')
        
        # ä¸ºæ‰€æœ‰å¯ç”¨çš„ STRM ä»»åŠ¡æ·»åŠ è°ƒåº¦
        for task in self.strm_tasks.values():
            if task.enabled:
                self._schedule_task(task, system_key='strm')
        
        # å¯åŠ¨ APScheduler
        self.scheduler.start()
        
        # å¯åŠ¨ä»»åŠ¡çº¿ç¨‹
        self.consumer_thread = threading.Thread(
            target=self._task_consumer,
            daemon=True,
            name="TaskConsumer"
        )
        self.consumer_thread.start()
        
        total_tasks = len(self.tasks) + len(self.strm_tasks)
        self._log(f"âœ“ è°ƒåº¦å™¨å·²å¯åŠ¨ (åŒæ­¥ä»»åŠ¡: {len(self.tasks)}, STRM ä»»åŠ¡: {len(self.strm_tasks)}, æ€»è®¡: {total_tasks})")
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨å’Œä»»åŠ¡çº¿ç¨‹"""
        if not self.is_running:
            self._log("âš  è°ƒåº¦å™¨æœªè¿è¡Œ")
            return
        
        self._log("æ­£åœ¨åœæ­¢è°ƒåº¦å™¨...")
        
        # åœæ­¢æ ‡å¿—
        self.is_running = False
        
        # åœæ­¢ APScheduler
        self.scheduler.shutdown(wait=False)
        
        # ç­‰å¾…ä»»åŠ¡çº¿ç¨‹ç»“æŸ
        if self.consumer_thread and self.consumer_thread.is_alive():
            self.consumer_thread.join(timeout=5)
        
        # ä¿å­˜ä»»åŠ¡çŠ¶æ€
        self.save_tasks()
        self.save_strm_tasks()
        
        self._log("âœ“ è°ƒåº¦å™¨å·²åœæ­¢")
    
    def _migrate_v0_to_v1(self, data: dict) -> dict:
        """å°†æ—  schema_version çš„æ—§é…ç½®è¿ç§»åˆ° v1 ç»“æ„
        - ç¡®ä¿ tasks ä¸ºåˆ—è¡¨
        - ç¡®ä¿ delete_queue ä¸ºåˆ—è¡¨
        """
        if not isinstance(data.get("tasks"), list):
            data["tasks"] = []
        if not isinstance(data.get("delete_queue"), list):
            data["delete_queue"] = []
        return data

    def _migrate_config(self, data: dict) -> dict:
        """æ ¹æ® schema_version å¯¹é…ç½®æ•°æ®è¿›è¡Œè¿ç§»"""
        old_version = data.get("schema_version", 0)
        try:
            version = int(old_version or 0)
        except (TypeError, ValueError):
            version = 0

        # ç›®å‰ä»…æœ‰ v0 -> v1 çš„è¿ç§»
        if version < 1:
            data = self._migrate_v0_to_v1(data)
            version = 1
            try:
                self._log(f"â„¹ï¸ æ£€æµ‹åˆ°æ—§ç‰ˆé…ç½®ï¼Œå·²ä» schema_version {old_version} è¿ç§»åˆ° {version}")
            except Exception:
                pass

        # å°†ç‰ˆæœ¬å·æå‡åˆ°å½“å‰ç‰ˆæœ¬
        data["schema_version"] = CONFIG_SCHEMA_VERSION
        return data

    def load_tasks(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½åŒæ­¥ä»»åŠ¡"""
        try:
            if not self.config_path.exists():
                self._log(f"â„¹ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºä»»åŠ¡åˆ—è¡¨")
                return
            
            with open(self.config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ ¹æ® schema_version å¯¹é…ç½®è¿›è¡Œè¿ç§»ï¼Œå…¼å®¹æ—§ç‰ˆæœ¬
            data = self._migrate_config(data)

            # è¿ç§»åˆ é™¤é˜Ÿåˆ—ä» JSON åˆ° SQLiteï¼ˆä¸€æ¬¡æ€§è¿ç§»ï¼‰
            if self.db.get_config("delete_queue_migrated") != "true":
                json_delete_queue = data.get("delete_queue", [])
                if json_delete_queue:
                    try:
                        migrated_count = self.db.migrate_from_json(json_delete_queue)
                        self._log(f"âœ“ å·²è¿ç§» {migrated_count} æ¡åˆ é™¤è®°å½•åˆ°æ•°æ®åº“")
                        self.db.set_config("delete_queue_migrated", "true")
                        self.db.set_config("migration_time", datetime.now().isoformat())
                    except Exception as e:
                        self._log(f"âš  è¿ç§»åˆ é™¤é˜Ÿåˆ—å¤±è´¥: {e}")
                else:
                    # æ²¡æœ‰æ—§æ•°æ®éœ€è¦è¿ç§»ï¼Œç›´æ¥æ ‡è®°ä¸ºå·²è¿ç§»
                    self.db.set_config("delete_queue_migrated", "true")

            # åŠ è½½å¾…åˆ é™¤æ–‡ä»¶é˜Ÿåˆ—ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰
            with self._delete_queue_lock:
                self.delete_queue = []  # ä¸å†ä» JSON åŠ è½½ï¼Œæ”¹ç”¨æ•°æ®åº“

            self.tasks.clear()
            loaded_count = 0
            failed_count = 0
            
            for task_data in data.get("tasks", []):
                try:
                    task = SyncTask.from_dict(task_data)
                    # é‡ç½®çŠ¶æ€ä¸º IDLEï¼ˆé¿å…å¯åŠ¨æ—¶çŠ¶æ€ä¸ä¸€è‡´ï¼‰
                    task.update_status(TaskStatus.IDLE)
                    self.tasks[task.id] = task
                    loaded_count += 1
                    
                except Exception as e:
                    task_name = task_data.get('name', 'æœªçŸ¥ä»»åŠ¡')
                    self._log(f"âœ— åŠ è½½ä»»åŠ¡å¤±è´¥: {task_name} - {str(e)}")
                    failed_count += 1
            
            # æç¤ºåŠ è½½ç»“æœ
            if failed_count > 0:
                self._log(f"âš ï¸ æœ‰ {failed_count} ä¸ªä»»åŠ¡åŠ è½½å¤±è´¥")
            
            self._log(f"âœ“ å·²åŠ è½½ {loaded_count} ä¸ªåŒæ­¥ä»»åŠ¡")
            
        except Exception as e:
            self._log(f"âœ— åŠ è½½åŒæ­¥ä»»åŠ¡é…ç½®å¤±è´¥: {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def load_strm_tasks(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½ STRM ä»»åŠ¡"""
        try:
            if not self.strm_config_path.exists():
                self._log(f"â„¹ï¸ STRM é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºä»»åŠ¡åˆ—è¡¨")
                return
            
            with open(self.strm_config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ ¹æ® schema_version å¯¹é…ç½®è¿›è¡Œè¿ç§»
            data = self._migrate_config(data)
            
            self.strm_tasks.clear()
            loaded_count = 0
            failed_count = 0
            
            for task_data in data.get("tasks", []):
                try:
                    task = StrmTask.from_dict(task_data)
                    # é‡ç½®çŠ¶æ€ä¸º IDLE
                    task.update_status(TaskStatus.IDLE)
                    self.strm_tasks[task.id] = task
                    loaded_count += 1
                    
                except Exception as e:
                    task_name = task_data.get('name', 'æœªçŸ¥ STRM ä»»åŠ¡')
                    self._log(f"âœ— åŠ è½½ STRM ä»»åŠ¡å¤±è´¥: {task_name} - {str(e)}")
                    failed_count += 1
            
            if failed_count > 0:
                self._log(f"âš ï¸ æœ‰ {failed_count} ä¸ª STRM ä»»åŠ¡åŠ è½½å¤±è´¥")
            
            self._log(f"âœ“ å·²åŠ è½½ {loaded_count} ä¸ª STRM ä»»åŠ¡")
            
        except Exception as e:
            self._log(f"âœ— åŠ è½½ STRM ä»»åŠ¡é…ç½®å¤±è´¥: {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def save_tasks(self):
        """ä¿å­˜åŒæ­¥ä»»åŠ¡åˆ°é…ç½®æ–‡ä»¶ï¼ˆåˆ é™¤é˜Ÿåˆ—å·²è¿ç§»åˆ°æ•°æ®åº“ï¼Œä¸å†ä¿å­˜åˆ° JSONï¼‰"""
        try:
            # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
            self.config_path.parent.mkdir(parents=True, exist_ok=True)

            data = {
                "schema_version": CONFIG_SCHEMA_VERSION,
                "tasks": [task.to_dict() for task in self.tasks.values()],
                "last_saved": datetime.now().isoformat(),
                # åˆ é™¤é˜Ÿåˆ—å·²è¿ç§»åˆ°æ•°æ®åº“ï¼ŒJSON ä¸­åªä¿ç•™ç©ºæ•°ç»„ï¼ˆå‘åå…¼å®¹ï¼‰
                "delete_queue": []
            }

            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # self._log(f"ğŸ’¾ åŒæ­¥ä»»åŠ¡é…ç½®å·²ä¿å­˜")
            
        except Exception as e:
            self._log(f"âœ— ä¿å­˜åŒæ­¥ä»»åŠ¡é…ç½®å¤±è´¥: {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def save_strm_tasks(self):
        """ä¿å­˜ STRM ä»»åŠ¡åˆ°é…ç½®æ–‡ä»¶"""
        try:
            # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
            self.strm_config_path.parent.mkdir(parents=True, exist_ok=True)
            
            data = {
                "schema_version": CONFIG_SCHEMA_VERSION,
                "tasks": [task.to_dict() for task in self.strm_tasks.values()],
                "last_saved": datetime.now().isoformat()
            }
            
            with open(self.strm_config_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # self._log(f"ğŸ’¾ STRM ä»»åŠ¡é…ç½®å·²ä¿å­˜")
            
        except Exception as e:
            self._log(f"âœ— ä¿å­˜ STRM ä»»åŠ¡é…ç½®å¤±è´¥: {str(e)}")
            import traceback
            self._log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def trigger_task_now(self, task_id: str) -> bool:
        """
        ç«‹å³è§¦å‘ä»»åŠ¡æ‰§è¡Œï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ å…¥é˜Ÿåˆ—
        """
        if task_id not in self.tasks:
            self._log(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return False
        
        task = self.tasks[task_id]
        
        if task.status != TaskStatus.IDLE:
            self._log(f"âš  ä»»åŠ¡çŠ¶æ€éç©ºé—²ï¼Œæ— æ³•ç«‹å³æ‰§è¡Œ: {task.name} (çŠ¶æ€: {task.status.value})")
            return False
        
        # æ‰‹åŠ¨è§¦å‘
        self._on_task_triggered(task_id)
        self._log(f"âš¡ æ‰‹åŠ¨è§¦å‘ä»»åŠ¡: {task.name}")
        return True
    
    def get_queue_size(self) -> int:
        """
        è·å–å½“å‰é˜Ÿåˆ—ä¸­ç­‰å¾…æ‰§è¡Œçš„ä»»åŠ¡æ•°
        
        Returns:
            é˜Ÿåˆ—å¤§å°
        """
        return self.task_queue.qsize()
    
    def get_next_run_time(self, task_id: str):
        """
        è·å–ä»»åŠ¡çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            datetime å¯¹è±¡ï¼Œå¦‚æœä»»åŠ¡æœªå¯ç”¨æˆ–ä¸å­˜åœ¨åˆ™è¿”å› None
        """
        if task_id not in self.tasks:
            return None
        
        task = self.tasks[task_id]
        
        # å¦‚æœä»»åŠ¡æœªå¯ç”¨ï¼Œè¿”å› None
        if not task.enabled:
            return None
        
        # ä» APScheduler è·å–ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        job = self.scheduler.get_job(task_id)
        if job and job.next_run_time:
            return job.next_run_time
        
        return None
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼šç¡®ä¿èµ„æºæ¸…ç†"""
        if self.is_running:
            self.stop()
        # å…³é—­æ•°æ®åº“è¿æ¥
        try:
            self.db.close()
        except Exception:
            pass
